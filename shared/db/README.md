Break down of why each component is necessary for a robust microservices architecture:

## Why Each DB Component Matters

### 1. **Connection Manager (`db.go`)**

**Problem it solves:**
- Without it, each service would manually create DB connections, leading to inconsistent error handling and connection leaks
- Services would duplicate connection logic across the codebase

**What it does:**
- **Connection Pooling** — Reuses connections instead of creating new ones for each query. This is CRITICAL because:
  - Creating a new TCP connection takes ~100ms
  - With 1000 requests/sec, you'd waste 100 seconds just on connections
  - Pooling keeps 5-25 connections alive, ready to reuse (reduces latency from 100ms to <1ms)

**Example scenario:**
```
WITHOUT pooling:
Request 1 → Create connection → Query → Close → 150ms

WITH pooling:
Request 1 → Reuse connection → Query → 5ms
Request 2 → Reuse connection → Query → 5ms
Request 3 → Reuse connection → Query → 5ms
```

- **Schema Awareness** — Each service gets its OWN database schema:
  ```
  Products Service uses: catalog_schema
  Cart Service uses: cart_schema  
  Orders Service uses: orders_schema
  Users Service uses: users_schema
  ```
  - All live in same PostgreSQL database but isolated from each other
  - Prevents accidental data leaks between services
  - If products service bugs corrupts data, orders service is unaffected

**Real-world analogy:** Like giving each tenant in an apartment building their own locked apartment (schema) instead of sharing keys to one shared space.

---

### 2. **Migration Runner (`migrations.go`)**

**Problem it solves:**
- Without versioning, teams manually run SQL files, leading to:
  - Developer A runs migration 001, Developer B runs 002 but then 001 again → database corruption
  - No audit trail of what changed when
  - Rollbacks are manual and error-prone
  - Can't reproduce production schema in local dev

**What it does:**
- **Version Control for Database** — Every schema change is tracked:
  ```
  Migration 001: Created users table ✓
  Migration 002: Added email_verified column ✓
  Migration 003: Added indexes ✓
  (If you deploy, all 3 run in order)
  ```

- **Rollback Safety** — Each migration has UP and DOWN:
  ```
  UP:   CREATE TABLE users (...)
  DOWN: DROP TABLE users
  
  If deployment fails at step 3, automatically run DOWN 3→2→1
  ```

- **Idempotency** — Migrations run only ONCE:
  ```
  First deploy: Run migrations 001, 002, 003
  Second deploy: See migrations 001-003 already ran → skip them
  (Don't try to CREATE TABLE users twice and fail)
  ```

**Without migrations, you'd have:**
```
Dev 1: "I ran the create tables script"
Dev 2: "Wait, I ran it twice by accident, did it fail?"
Dev 3: "Production is missing the inventory_history table"
QA Lead: "How do I reset the test database?"
```

---

### 3. **Schema Utilities (`schema.go`)**

**Problem it solves:**
- Services need to verify database health, check if tables exist before querying them
- Without utilities, you'd query a table that doesn't exist → crash
- Hard to debug: "Why did the products service fail?" Answer: "We never ran migrations"

**What it does:**
- **Health Checks** — Services verify tables exist before starting:
  ```go
  // At startup
  if !schemaManager.TableExists("products") {
      log.Fatal("products table not found - migrations failed!")
  }
  ```

- **Dynamic Schema Discovery** — List all tables to verify integrity:
  ```go
  tables := schemaManager.ListTables()
  // Logs: [products, categories, inventory_history]
  // Good, all expected tables exist
  ```

- **Current Schema Verification** — Ensure correct schema is active:
  ```go
  current := schemaManager.GetCurrentSchema()
  if current != "catalog_schema" {
      log.Fatal("Wrong schema active! Using " + current)
  }
  ```

**Real-world scenario:**
```
9 AM: Deploy orders service with new orders table schema
9:01 AM: Orders service crashes - "relation \"orders\" does not exist"
Root cause: Migrations runner didn't run
With utilities: Service would check for table at startup and fail FAST
vs. Silent failure: Crashes mid-request when first customer places order
```

---

### 4. **Idempotency Tracking (`idempotency.go`)**

**Problem it solves:**
- In event-driven systems, events can be delivered MULTIPLE times (network retries)
- Without idempotency, duplicates cause chaos:

**Example without idempotency:**
```
Event: "ProductStockReserved" (event_id: abc123, quantity: 5)

First attempt: 
  - Received event
  - Reserved 5 units
  - Network timeout before ACK

Retry (event delivered again):
  - Received event again (same event_id)
  - Reserved 5 MORE units (WRONG! Should have been idempotent)
  - Now inventory is 10 units less than it should be
```

**With idempotency tracking:**
```
Event received (event_id: abc123)
Check: Has event_id abc123 been processed? → NO
Process: Reserve 5 units
Record: Mark event abc123 as processed

Event retried (same event_id)
Check: Has event_id abc123 been processed? → YES (found in DB)
Skip processing (already done)
Return: "Already processed this event"
```

**Why this matters:**
- RabbitMQ guarantees "at least once" delivery, not "exactly once"
- Network hiccups cause retries constantly in production
- Without idempotency: Every network glitch causes data corruption
- With idempotency: Retries are safe, data stays consistent

**Real-world impact:**
```
10,000 orders/day
Average 2% network failures = 200 failed transmissions
Each triggers 3 retries = 600 duplicate events
Without idempotency: 600 erroneous state changes
With idempotency: All 600 safely ignored
```

---

### How It All Fits Together

```
┌─────────────────────────────────────────┐
│         Products Service                │
├─────────────────────────────────────────┤
│                                         │
│  Handler receives: "ProductCreated"     │
│         ↓                               │
│  Idempotency Check:                     │
│    Is event_id already processed?       │ ← IdempotencyStore
│         ↓                               │
│  Get Connection:                        │
│    Reuse from pool, set to              │ ← Connection Manager
│    catalog_schema                       │
│         ↓                               │
│  Verify Database Ready:                 │
│    Does products table exist?           │ ← Schema Utilities
│         ↓                               │
│  Execute Transaction:                   │
│    INSERT product data                  │
│    (Auto rollback if fails)             │ ← Migrations (created tables)
│         ↓                               │
│  Mark Processed:                        │
│    Record event_id as processed         │ ← IdempotencyStore
│         ↓                               │
│  Publish Event:                         │
│    Send "ProductCreated" to RabbitMQ    │
└─────────────────────────────────────────┘
```

---

### Summary: Why You Need All This

| Component | Problem Without It | Real Cost |
|-----------|-------------------|-----------|
| **Connection Manager** | New connections for each query | 100ms latency × 1000 req/sec = 100 seconds wasted |
| **Migration Runner** | Manual DB updates, no rollback | Corrupted production DB, 12 hours to fix |
| **Schema Utilities** | Can't verify DB health | Silent failures, crashes mid-transaction |
| **Idempotency Tracking** | Duplicate event processing | Double billing, inventory corruption, angry customers |

**Think of it like building a house:**
- **Connection Manager** = Electrical wiring (reuses power efficiently)
- **Migration Runner** = Building permits (tracks what was built when)
- **Schema Utilities** = Home inspection (verify house is safe before moving in)
- **Idempotency Tracking** = Receipt system (don't charge for same item twice)

docker exec -it prost-postgres psql -U prost_admin -d prost


PostgreSQL Server
├── Database: prost
│   ├── Schema: catalog
│   │   ├── products id | name | description | price | category_id | sku | stock_quantity | image_url | created_at | updated_at | deleted_at 
│   │               ----+------+-------------+-------+-------------+-----+----------------+-----------+------------+------------+------------
│   │   ├── categories   id | name | description | created_at | updated_at | deleted_at 
│   │                   ----+------+-------------+------------+------------+------------
│   │   └── inventory_reservations  id | product_id | quantity | order_id | reservation_id | status | created_at | expires_at | released_at
│   │   │                          ----+------------+----------+----------+----------------+--------+------------+------------+-------------
│   │   └── idempotency_records  id | event_id | service_name | action | result | created_at 
│   │                           ----+----------+--------------+--------+--------+------------
│   ├── Schema: users
│   │   └── users  id | email | username | password_hash | created_at | updated_at | deleted_at 
│   │             ----+-------+----------+---------------+------------+------------+------------
│   │   └── idempotency_records  id | event_id | service_name | action | result | created_at 
│   │                           ----+----------+--------------+--------+--------+------------
│   ├── Schema: cart
│   │   ├── carts   id | user_id | status | total | created_at | updated_at | abandoned_at 
│   │              ----+---------+--------+-------+------------+------------+--------------
│   │   └── cart_items   id | cart_id | product_id | quantity | price | created_at | updated_at 
│   │                   ----+---------+------------+----------+-------+------------+------------
│   │   └── idempotency_records  id | event_id | service_name | action | result | created_at 
│   │                           ----+----------+--------------+--------+--------+------------
│   └── Schema: orders
│   │   ├── orders  id | user_id | cart_id | total | status | saga_correlation_id | created_at | updated_at | shipped_at | delivered_at | cancelled_at 
│   │              ----+---------+---------+-------+--------+---------------------+------------+------------+------------+--------------+--------------
│   │   └── order_items  id | order_id | product_id | quantity | price | created_at 
│   │                   ----+----------+------------+----------+-------+------------
│   │   └── idempotency_records  id | event_id | service_name | action | result | created_at 
│   │                           ----+----------+--------------+--------+--------+------------
│   │   └── compensation_log   id | order_id | saga_correlation_id | compensation_event | compensation_payload | status | created_at | completed_at 
│   │                         ----+----------+---------------------+--------------------+----------------------+--------+------------+--------------
│   │   └── inventory_reservations   id | order_id | product_id | quantity | reservation_id | status | created_at | expires_at | released_at | fulfilled_at 
│   │                               ----+----------+------------+----------+----------------+--------+------------+------------+-------------+--------------
│   │   └── saga_states   id | correlation_id | saga_type | status | order_id | payload | compensation_log | created_at | updated_at | expires_at 
│   │                    ----+----------------+-----------+--------+----------+---------+------------------+------------+------------+------------
│   │
├── Database: analytics
│   └── Schema: public
│       └── reports

```sql
-- List all schemas
\dn

-- List tables in catalog schema
\dt catalog.*

-- List tables in users schema
\dt users.*

-- List tables in cart schema
\dt cart.*

-- List tables in orders schema
\dt orders.*

-- View structure of products table
\d catalog.products

-- View structure of categories table
\d catalog.categories

-- View all products
SELECT * FROM catalog.products;

-- View all categories
SELECT * FROM catalog.categories;

-- Count products and categories
SELECT COUNT(*) FROM catalog.products;
SELECT COUNT(*) FROM catalog.categories;

-- View sample data with formatting
SELECT id, name, price, stock_quantity FROM catalog.products LIMIT 10;
```

## Idempotency

No matter how many time you repeat an operation it should result in same outcome.

RabbitMQ guarantees atleast once delivery of events, so will retry delivering the event until it receives an ACK from consumer. This will lead to duplicate evevnts being published to consumers in case of any network failures while receiving ACK. In order to handle that scenario we implement idempotency.

How it works?

Every event has a unique ID, before processing that event it is checked if it is processed or not by the consuming service.